<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Samuel Carton</title> <meta name="author" content="Samuel Carton"/> <meta name="description" content="Assistant professor of computer science at University of New Hampshire. "/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://shcarton.github.io/publications/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Samuel Carton</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p><a href="https://scholar.google.com/citations?user=Zx7iVcUAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer">Google Scholar</a> </p> <div class="publications"> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="carton_what_2022" class="col-sm-8"> <div class="title">What to Learn, and How: Toward Effective Learning from Rationales</div> <div class="author"> Samuel Carton, Surya Kanoria, and Chenhao Tan</div> <div class="periodical"> <em>Findings of the Association for Computational Linguistics (ACL)</em> 2022 </div> <div class="links"> <a href="/assets/pdf/Carton%20et%20al.%20-%202022%20-%20What%20to%20Learn,%20and%20How%20Toward%20Effective%20Learning%20.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="lai_human-ai_2022" class="col-sm-8"> <div class="title">Human-AI Collaboration via Conditional Delegation: A Case Study of Content Moderation</div> <div class="author"> Vivian Lai, Samuel Carton, Rajat Bhatnagar, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Q Vera Liao, Yunfeng Zhang, Chenhao Tan' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Lai%20et%20al.%20-%202022%20-%20Human-AI%20Collaboration%20via%20Conditional%20Delegation.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Despite impressive performance in many benchmark datasets, AI models can still make mistakes, especially among out-of-distribution examples. It remains an open question how such imperfect models can be used effectively in collaboration with humans. Prior work has focused on AI assistance that helps people make individual high-stakes decisions, which is not scalable for a large amount of relatively low-stakes decisions, e.g., moderating social media comments. Instead, we propose conditional delegation as an alternative paradigm for human-AI collaboration where humans create rules to indicate trustworthy regions of a model. Using content moderation as a testbed, we develop novel interfaces to assist humans in creating conditional delegation rules and conduct a randomized experiment with two datasets to simulate in-distribution and outof-distribution scenarios. Our study demonstrates the promise of conditional delegation in improving model performance and provides insights into design for this novel paradigm, including the effect of AI explanations.</p> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="garbacea_explainable_2021" class="col-sm-8"> <div class="title">Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification</div> <div class="author"> Cristina Garbacea, Mengtian Guo, Samuel Carton, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Qiaozhu Mei' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL)</em> Aug 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Garbacea%20et%20al.%20-%202021%20-%20Explainable%20Prediction%20of%20Text%20Complexity%20The%20Mis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Text simplification reduces the language complexity of professional content for accessibility purposes. End-to-end neural network models have been widely adopted to directly generate the simplified version of input text, usually functioning as a blackbox. We show that text simplification can be decomposed into a compact pipeline of tasks to ensure the transparency and explainability of the process. The first two steps in this pipeline are often neglected: 1) to predict whether a given piece of text needs to be simplified, and 2) if yes, to identify complex parts of the text. The two tasks can be solved separately using either lexical or deep learning methods, or solved jointly. Simply applying explainable complexity prediction as a preliminary step, the out-of-sample text simplification performance of the state-of-the-art, black-box simplification models can be improved by a large margin.</p> </div> </div> </div> </li></ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="carton_feature-based_2020" class="col-sm-8"> <div class="title">Feature-Based Explanations Don’t Help People Detect Misclassifications of Online Toxicity</div> <div class="author"> Samuel Carton, Qiaozhu Mei, and Paul Resnick</div> <div class="periodical"> <em>In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM)</em> May 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Carton%20et%20al.%20-%202020%20-%20Feature-Based%20Explanations%20Don%E2%80%99t%20Help%20People%20Detec.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We present an experimental assessment of the impact of feature attribution-style explanations on human performance in predicting the consensus toxicity of social media posts with advice from an unreliable machine learning model. By doing so we add to a small but growing body of literature inspecting the utility of interpretable machine learning in terms of human outcomes. We also evaluate interpretable machine learning for the first time in the important domain of online toxicity, where fully-automated methods have faced criticism as being inadequate as a measure of toxic behavior.We find that, contrary to expectations, explanations have no significant impact on accuracy or agreement with model predictions, through they do change the distribution of subject error somewhat while reducing the cognitive burden of the task for subjects. Our results contribute to the recognition of an intriguing expectation gap in the field of interpretable machine learning between the general excitement the field has engendered and the ambiguous results of recent experimental work, including this study.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="carton_evaluating_2020" class="col-sm-8"> <div class="title">Evaluating and Characterizing Human Rationales</div> <div class="author"> Samuel Carton, Anirudh Rathore, and Chenhao Tan</div> <div class="periodical"> <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em> Nov 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Carton%20et%20al.%20-%202020%20-%20Evaluating%20and%20Characterizing%20Human%20Rationales.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Two main approaches for evaluating the quality of machine-generated rationales are: 1) using human rationales as a gold standard; and 2) automated metrics based on how rationales affect model behavior. An open question, however, is how human rationales fare with these automatic metrics. Analyzing a variety of datasets and models, we find that human rationales do not necessarily perform well on these metrics. To unpack this finding, we propose improved metrics to account for model-dependent baseline performance. We then propose two methods to further characterize rationale quality, one based on model retraining and one on using “fidelity curves” to reveal properties such as irrelevance and redundancy. Our work leads to actionable suggestions for evaluating and characterizing rationales.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="lai_harnessing_2020" class="col-sm-8"> <div class="title">Harnessing Explanations to Bridge AI and Humans</div> <div class="author"> Vivian Lai, Samuel Carton, and Chenhao Tan</div> <div class="periodical"> <em>In Proceedings of the CHI 2020 Fair &amp; Responsible AI Workshop</em> Mar 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Lai%20et%20al.%20-%202020%20-%20Harnessing%20Explanations%20to%20Bridge%20AI%20and%20Humans.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Machine learning models are increasingly integrated into societally critical applications such as recidivism prediction and medical diagnosis, thanks to their superior predictive power. In these applications, however, full automation is often not desired due to ethical and legal concerns. The research community has thus ventured into developing interpretable methods that explain machine predictions. While these explanations are meant to assist humans in understanding machine predictions and thereby allowing humans to make better decisions, this hypothesis is not supported in many recent studies. To improve human decision-making with AI assistance, we propose future directions for closing the gap between the efficacy of explanations and improvement in human performance.</p> </div> </div> </div> </li> </ol> <h2 class="year">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="garbacea_judge_2019" class="col-sm-8"> <div class="title">Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation</div> <div class="author"> Cristina Garbacea, Samuel Carton, Shiyan Yan, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Qiaozhu Mei' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em> Nov 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Garbacea%20et%20al.%20-%202019%20-%20Judge%20the%20Judges%20A%20Large-Scale%20Evaluation%20Study%20o.pdf:" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We conduct a large-scale, systematic study to evaluate the existing evaluation methods for natural language generation in the context of generating online product reviews. We compare human-based evaluators with a variety of automated evaluation procedures, including discriminative evaluators that measure how well machine-generated text can be distinguished from human-written text, as well as word overlap metrics that assess how similar the generated text compares to human-written references. We determine to what extent these different evaluators agree on the ranking of a dozen of state-of-the-art generators for online product reviews. We find that human evaluators do not correlate well with discriminative evaluators, leaving a bigger question of whether adversarial accuracy is the correct objective for natural language generation. In general, distinguishing machine-generated text is challenging even for human evaluators, and human decisions correlate better with lexical overlaps. We find lexical diversity an intriguing metric that is indicative of the assessments of different evaluators. A post-experiment survey of participants provides insights into how to evaluate and improve the quality of natural language generation systems.</p> </div> </div> </div> </li></ol> <h2 class="year">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="helsby_early_2018" class="col-sm-8"> <div class="title">Early Intervention Systems: Predicting Adverse Interactions Between Police and the Public</div> <div class="author"> Jennifer Helsby, Samuel Carton, Kenneth Joseph, and <span class="more-authors" title="click to view 9 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '9 more authors' ? 'Ayesha Mahmud, Youngsoo Park, Andrea Navarrete, Klaus Ackermann, Joe Walsh, Lauren Haynes, Crystal Cody, Major Estella Patterson, Rayid Ghani' : '9 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">9 more authors</span> </div> <div class="periodical"> <em>Criminal Justice Policy Review</em> Mar 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Helsby%20et%20al.%20-%202018%20-%20Early%20Intervention%20Systems%20Predicting%20Adverse%20Int.pdf:files/3385/Helsby%20et%20al.%20-%202018%20-%20Early%20Intervention%20Systems%20Predicting%20Adverse%20Int.pdf:application/pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Adverse interactions between police and the public hurt police legitimacy, cause harm to both officers and the public, and result in costly litigation. Early intervention systems (EISs) that flag officers considered most likely to be involved in one of these adverse events are an important tool for police supervision and for targeting interventions such as counseling or training. However, the EISs that exist are not data-driven and based on supervisor intuition. We have developed a data-driven EIS that uses a diverse set of data sources from the Charlotte-Mecklenburg Police Department and machine learning techniques to more accurately predict the officers who will have an adverse event. Our approach is able to significantly improve accuracy compared with their existing EIS: Preliminary results indicate a 20% reduction in false positives and a 75% increase in true positives.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="carton_extractive_2018" class="col-sm-8"> <div class="title">Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts</div> <div class="author"> Samuel Carton, Qiaozhu Mei, and Paul Resnick</div> <div class="periodical"> <em>In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em> Oct 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Carton%20et%20al.%20-%202018%20-%20Extractive%20Adversarial%20Networks%20High-Recall%20Expla.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We introduce an adversarial method for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the attention for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate “default” behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.</p> </div> </div> </div> </li> </ol> <h2 class="year">2017</h2> <ol class="bibliography"></ol> <h2 class="year">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="carton_identifying_2016" class="col-sm-8"> <div class="title">Identifying Police Officers at Risk of Adverse Events</div> <div class="author"> Samuel Carton, Rayid Ghani, Jennifer Helsby, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Kenneth Joseph, Ayesha Mahmud, Youngsoo Park, Joe Walsh, Crystal Cody, CPT Estella Patterson, Lauren Haynes' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</em> Oct 2016 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Carton%20et%20al.%20-%202016%20-%20Identifying%20Police%20Officers%20at%20Risk%20of%20Adverse%20Eve.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Adverse events between police and the public, such as deadly shootings or instances of racial proﬁling, can cause serious or deadly harm, damage police legitimacy, and result in costly litigation. Evidence suggests these events can be prevented by targeting interventions based on an Early Intervention System (EIS) that ﬂags police oﬃcers who are at a high risk for involvement in such adverse events. Today’s EIS are not data-driven and typically rely on simple thresholds based entirely on expert intuition. In this paper, we describe our work with the Charlotte-Mecklenburg Police Department (CMPD) to develop a machine learning model to predict which oﬃcers are at risk for an adverse event. Our approach signiﬁcantly outperforms CMPD’s existing EIS, increasing true positives by ∼ 12% and decreasing false positives by ∼ 32%. Our work also sheds light on features related to oﬃcer characteristics, situational factors, and neighborhood factors that are predictive of adverse events. This work provides a starting point for police departments to take a comprehensive, data-driven approach to improve policing and reduce harm to both oﬃcers and members of the public.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="tang_context-aware_2016" class="col-sm-8"> <div class="title">Context-aware Natural Language Generation with Recurrent Neural Networks</div> <div class="author"> Jian Tang, Yifan Yang, Sam Carton, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ming Zhang, Qiaozhu Mei' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em> Nov 2016 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Tang%20et%20al.%20-%202016%20-%20Context-aware%20Natural%20Language%20Generation%20with%20Rec.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This paper studied generating natural languages at particular contexts or situations. We proposed two novel approaches which encode the contexts into a continuous semantic representation and then decode the semantic representation into text sequences with recurrent neural networks. During decoding, the context information are attended through a gating mechanism, addressing the problem of long-range dependency caused by lengthy sequences. We evaluate the effectiveness of the proposed approaches on user review data, in which rich contexts are available and two informative contexts, sentiments and products, are selected for evaluation. Experiments show that the fake reviews generated by our approaches are very natural. Results of fake review detection with human judges show that more than 50% of the fake reviews are misclassiﬁed as the real reviews, and more than 90% are misclassiﬁed by existing state-of-the-art fake review detection algorithm.</p> </div> </div> </div> </li> </ol> <h2 class="year">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="carton_audience_2015" class="col-sm-8"> <div class="title">Audience Analysis for Competing Memes in Social Media</div> <div class="author"> Samuel Carton, Souneil Park, Nicole Zeffer, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Eytan Adar, Qiaozhu Mei, Paul Resnick' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Ninth International AAAI Conference on Web and Social Media (ICWSM)</em> Apr 2015 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Carton%20et%20al.%20-%202015%20-%20Audience%20Analysis%20for%20Competing%20Memes%20in%20Social%20Me.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Existing tools for exploratory analysis of information diffusion in social media focus on the message senders who actively diffuse the meme. We develop a tool for audience analysis, focusing on the people who are passively exposed to the messages, with a special emphasis on competing memes such as propagations and corrections of a rumor. In such competing meme diffusions, important questions include which meme reached a bigger total audience, the overlap in audiences of the two, and whether exposure to one meme inhibited propagation of the other. We track audience members’ states of interaction, such as having been exposed to one meme or another or both. We analyze the marginal impact of each message in terms of the number of people who transition between states as a result of that message. These marginal impacts can be computed efficiently, even for diffusions involving thousands of senders and millions of receivers. The marginal impacts provide the raw material for an interactive tool, RumorLens, that includes a Sankey diagram and a network diagram. We validate the utility of the tool through a case study of nine rumor diffusions. We validate the usability of the tool through a user study, showing that nonexperts are able to use it to answer audience analysis questions.</p> </div> </div> </div> </li></ol> <h2 class="year">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="resnick_rumorlens:_2014" class="col-sm-8"> <div class="title">RumorLens: A System for Analyzing the Impact of Rumors and Corrections in Social Media</div> <div class="author"> Paul Resnick, Samuel Carton, Souneil Park, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yuncheng Shen, Nicole Zeffer' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Computation + Journalism Symposium</em> Apr 2014 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Resnick%20et%20al.%20-%202014%20-%20RumorLens%20A%20System%20for%20Analyzing%20the%20Impact%20of%20Ru.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Some rumors spread quickly and widely through social media. Journalists write about them, both to help the public understand whether they are true, and to help the public understand how widely misinformation and corrections have spread, and how they did. We describe RumorLens, a suite of interactive tools that are designed to help journalists identify new rumors on Twitter and assess the audiences that rumor and correction tweets have reached. The tools make efficient use of human labor to assess whether a rumor’s content is interesting enough to warrant further exploration, to label tweets as spreading, correcting, or unrelated to the rumor, and to analyze the rumor visually. Behind the scenes, automated learning and computation amplifies the effectiveness of that labor, making it feasible to engage journalists and the broader public to run a continuous rumor-monitoring service.</p> </div> </div> </div> </li></ol> <h2 class="year">2013</h2> <ol class="bibliography"></ol> <h2 class="year">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="bao_omnipedia:_2012" class="col-sm-8"> <div class="title">Omnipedia: bridging the wikipedia language gap</div> <div class="author"> Patti Bao, Brent Hecht, Samuel Carton, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Mahmood Quaderi, Michael Horn, Darren Gergle' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems (CHI)</em> Apr 2012 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Bao%20et%20al.%20-%202012%20-%20Omnipedia%20bridging%20the%20wikipedia%20language%20gap.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We present Omnipedia, a system that allows Wikipedia readers to gain insight from up to 25 language editions of Wikipedia simultaneously. Omnipedia highlights the similarities and differences that exist among Wikipedia language editions, and makes salient information that is unique to each language as well as that which is shared more widely. We detail solutions to numerous front-end and algorithmic challenges inherent to providing users with a multilingual Wikipedia experience. These include visualizing content in a language-neutral way and aligning data in the face of diverse information organization strategies. We present a study of Omnipedia that characterizes how people interact with information using a multilingual lens. We found that users actively sought information exclusive to unfamiliar language editions and strategically compared how language editions defined concepts. Finally, we briefly discuss how Omnipedia generalizes to other domains facing language barriers.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hecht_explanatory_2012" class="col-sm-8"> <div class="title">Explanatory semantic relatedness and explicit spatialization for exploratory search</div> <div class="author"> Brent Hecht, Samuel H. Carton, Mahmood Quaderi, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Johannes Schöning, Martin Raubal, Darren Gergle, Doug Downey' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval (SIGIR)</em> Apr 2012 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Hecht%20et%20al.%20-%202012%20-%20Explanatory%20semantic%20relatedness%20and%20explicit%20spat.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Exploratory search, in which a user investigates complex concepts, is cumbersome with today’s search engines. We present a new exploratory search approach that generates interactive visualizations of query concepts using thematic cartography (e.g. choropleth maps, heat maps). We show how the approach can be applied broadly across both geographic and non-geographic contexts through explicit spatialization, a novel method that leverages any figure or diagram – from a periodic table, to a parliamentary seating chart, to a world map – as a spatial search environment. We enable this capability by introducing explanatory semantic relatedness measures. These measures extend frequently-used semantic relatedness measures to not only estimate the degree of relatedness between two concepts, but also generate human-readable explanations for their estimates by mining Wikipedia’s text, hyperlinks, and category structure. We implement our approach in a system called Atlasify, evaluate its key components, and present several use cases.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Samuel Carton. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>